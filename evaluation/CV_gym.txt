KFOLD
12-32s
NO OUTLIERS DETECTION + NO SCALING

SVC
{'fit_time': array([0.72730303, 0.91474891, 0.74935293, 0.69255018, 0.82231593]), 'score_time': array([0.00261402, 0.00248718, 0.00246882, 0.00250387, 0.00251198]), 'test_score': array([0.27692308, 0.22051282, 0.28205128, 0.25257732, 0.28350515])}
Accuracy Score:
0.263103802672148
Classification Report:
              precision    recall  f1-score   support

           0       0.26      0.16      0.20       239
           1       0.25      0.04      0.06       221
           2       0.26      0.39      0.31       255
           3       0.27      0.43      0.33       258

    accuracy                           0.26       973
   macro avg       0.26      0.25      0.23       973
weighted avg       0.26      0.26      0.23       973

Confusion Matrix:
[[ 38  10  89 102]
 [ 35   8  88  90]
 [ 38   8  99 110]
 [ 37   6 104 111]]

 RF
{'fit_time': array([0.10643721, 0.10510111, 0.102211  , 0.10211492, 0.10403991]), 'score_time': array([0.0032959 , 0.0034759 , 0.00317788, 0.00312209, 0.00308514]), 'test_score': array([0.27692308, 0.21025641, 0.25641026, 0.21134021, 0.23195876])}
Accuracy Score:
0.2569373072970195
Classification Report:
              precision    recall  f1-score   support

           0       0.25      0.24      0.24       239
           1       0.23      0.16      0.19       221
           2       0.28      0.32      0.30       255
           3       0.26      0.29      0.28       258

    accuracy                           0.26       973
   macro avg       0.25      0.25      0.25       973
weighted avg       0.25      0.26      0.25       973

Confusion Matrix:
[[57 42 70 70]
 [57 36 60 68]
 [56 39 81 79]
 [60 41 81 76]]

 MLP
{'fit_time': array([0.05666518, 0.10680294, 0.07808709, 0.04527783, 0.08017015]), 'score_time': array([0.00062394, 0.00067186, 0.00071192, 0.00057602, 0.00074601]), 'test_score': array([0.19487179, 0.3025641 , 0.29230769, 0.25773196, 0.27835052])}
Accuracy Score:
0.23843782117163412
Classification Report:
              precision    recall  f1-score   support

           0       0.24      0.13      0.17       239
           1       0.19      0.11      0.14       221
           2       0.25      0.35      0.29       255
           3       0.24      0.33      0.28       258

    accuracy                           0.24       973
   macro avg       0.23      0.23      0.22       973
weighted avg       0.23      0.24      0.23       973

Confusion Matrix:
[[32 35 96 76]
 [26 25 82 88]
 [33 34 90 98]
 [44 39 90 85]]

_______________________________________________________________________________________________

NO OUTLIERS DETECTION + SCALING

{'fit_time': array([0.04717112, 0.04093814, 0.03838301, 0.03923106, 0.03853965]), 'score_time': array([0.00267696, 0.0024569 , 0.00240898, 0.00226998, 0.00238824]), 'test_score': array([0.25128205, 0.24615385, 0.29230769, 0.21649485, 0.2371134 ])}
Accuracy Score:
0.24871531346351491
Classification Report:
              precision    recall  f1-score   support

           0       0.27      0.34      0.30       239
           1       0.21      0.23      0.22       221
           2       0.27      0.23      0.25       255
           3       0.24      0.20      0.22       258

    accuracy                           0.25       973
   macro avg       0.25      0.25      0.25       973
weighted avg       0.25      0.25      0.25       973

Confusion Matrix:
[[82 51 47 59]
 [66 50 61 44]
 [73 67 59 56]
 [84 75 48 51]]
{'fit_time': array([0.10982084, 0.10770893, 0.10319686, 0.10634613, 0.10798192]), 'score_time': array([0.00340724, 0.00379491, 0.00349307, 0.00328708, 0.00350881]), 'test_score': array([0.28205128, 0.18974359, 0.27692308, 0.2371134 , 0.24226804])}
Accuracy Score:
0.24357656731757452
Classification Report:
              precision    recall  f1-score   support

           0       0.22      0.21      0.22       239
           1       0.22      0.14      0.18       221
           2       0.26      0.30      0.28       255
           3       0.25      0.30      0.28       258

    accuracy                           0.24       973
   macro avg       0.24      0.24      0.24       973
weighted avg       0.24      0.24      0.24       973

Confusion Matrix:
[[51 41 73 74]
 [50 32 65 74]
 [63 36 76 80]
 [64 34 82 78]]
{'fit_time': array([1.17593813, 0.89191604, 1.07115197, 1.000911  , 0.75638103]), 'score_time': array([0.0008049 , 0.00078702, 0.00077486, 0.00079894, 0.00078893]), 'test_score': array([0.24102564, 0.24615385, 0.25641026, 0.25773196, 0.23195876])}
Accuracy Score:
0.2528263103802672
Classification Report:
              precision    recall  f1-score   support

           0       0.21      0.20      0.20       239
           1       0.22      0.22      0.22       221
           2       0.29      0.28      0.28       255
           3       0.28      0.30      0.29       258

    accuracy                           0.25       973
   macro avg       0.25      0.25      0.25       973
weighted avg       0.25      0.25      0.25       973

Confusion Matrix:
[[47 59 63 70]
 [57 49 57 58]
 [56 56 72 71]
 [63 57 60 78]]


_______________________________________________________________________________________________

NO OUTLIERS DETECTION + SCALING + FEATURE SELECTION

{'fit_time': array([1.65956497, 3.10958791, 1.03095794, 3.17575908, 4.24584198]), 'score_time': array([0.00258708, 0.00233293, 0.00225711, 0.00248885, 0.00230598]), 'test_score': array([0.28717949, 0.26153846, 0.25641026, 0.26804124, 0.24742268])}
Accuracy Score:
0.2641315519013361
Classification Report:
              precision    recall  f1-score   support

           0       0.25      0.18      0.21       239
           1       0.28      0.05      0.08       221
           2       0.27      0.43      0.33       255
           3       0.27      0.36      0.31       258

    accuracy                           0.26       973
   macro avg       0.27      0.26      0.23       973
weighted avg       0.27      0.26      0.24       973

Confusion Matrix:
[[ 43   8 104  84]
 [ 36  11  89  85]
 [ 47  10 109  89]
 [ 46  10 108  94]]
{'fit_time': array([0.06740785, 0.06643081, 0.06519818, 0.07318711, 0.06355095]), 'score_time': array([0.00328231, 0.00339723, 0.00330186, 0.00337625, 0.00312304]), 'test_score': array([0.21025641, 0.25641026, 0.24102564, 0.23195876, 0.2371134 ])}
Accuracy Score:
0.24152106885919836
Classification Report:
              precision    recall  f1-score   support

           0       0.23      0.22      0.22       239
           1       0.24      0.22      0.23       221
           2       0.25      0.27      0.26       255
           3       0.23      0.25      0.24       258

    accuracy                           0.24       973
   macro avg       0.24      0.24      0.24       973
weighted avg       0.24      0.24      0.24       973

Confusion Matrix:
[[52 46 68 73]
 [51 49 58 63]
 [61 49 69 76]
 [60 56 77 65]]
{'fit_time': array([0.45668578, 0.56202888, 0.41541791, 0.49986601, 0.78171897]), 'score_time': array([0.00086808, 0.00083303, 0.00105   , 0.000844  , 0.00084615]), 'test_score': array([0.27179487, 0.24615385, 0.23076923, 0.21134021, 0.24226804])}
Accuracy Score:
0.23843782117163412
Classification Report:
              precision    recall  f1-score   support

           0       0.24      0.25      0.24       239
           1       0.22      0.16      0.18       221
           2       0.24      0.24      0.24       255
           3       0.25      0.29      0.27       258

    accuracy                           0.24       973
   macro avg       0.24      0.24      0.23       973
weighted avg       0.24      0.24      0.24       973

Confusion Matrix:
[[59 39 69 72]
 [54 35 66 66]
 [69 38 62 86]
 [67 49 66 76]]


 _______________________________________________________________________________________________
OUTLIERS DETECTION + SCALING

 K-Fold CV Results:
SVM: Mean Accuracy = 0.2312
              precision    recall  f1-score   support

           0       0.23      0.30      0.26       239
           1       0.19      0.19      0.19       221
           2       0.26      0.24      0.25       255
           3       0.25      0.20      0.22       258

    accuracy                           0.23       973
   macro avg       0.23      0.23      0.23       973
weighted avg       0.23      0.23      0.23       973

Random Forest: Mean Accuracy = 0.2456
              precision    recall  f1-score   support

           0       0.25      0.23      0.24       239
           1       0.28      0.19      0.23       221
           2       0.28      0.32      0.30       255
           3       0.25      0.28      0.26       258

    accuracy                           0.26       973
   macro avg       0.26      0.26      0.26       973
weighted avg       0.26      0.26      0.26       973

MLP: Mean Accuracy = 0.2477
              precision    recall  f1-score   support

           0       0.23      0.24      0.23       239
           1       0.19      0.18      0.19       221
           2       0.27      0.27      0.27       255
           3       0.23      0.22      0.22       258

    accuracy                           0.23       973
   macro avg       0.23      0.23      0.23       973
weighted avg       0.23      0.23      0.23       973




{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b76998-1885-456f-833d-ef2a8474029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model: DecisionTreeClassifier\n",
      "Initial parameters: [8, 9]\n",
      "scores=0.9029999999999999\n",
      "Neighborhood algorithm: DecisionTreeClassifier, parameters: [7, 11]\n",
      "scores=0.899\n",
      "Neighborhood algorithm: DecisionTreeClassifier, parameters: [10, 16]\n",
      "scores=0.8899999999999999\n",
      "Neighborhood algorithm: LogisticRegression, parameters: [6.518866122660014, 'l2']\n",
      "scores=0.821\n",
      "Neighborhood algorithm: SVC, parameters: [8.695229067783705, 0.18629852144152304]\n",
      "scores=0.923\n",
      "Neighborhood algorithm: RandomForestClassifier, parameters: [91, 7]\n",
      "scores=0.9309999999999998\n",
      "Neighborhood algorithm: LogisticRegression, parameters: [2.525364652116174, 'l2']\n",
      "scores=0.821\n",
      "Neighborhood algorithm: MLPClassifier, parameters: [0.054085016451561135, 0.05595817111672631]\n",
      "scores=0.943\n",
      "Neighborhood algorithm: RandomForestClassifier, parameters: [22, 1]\n",
      "scores=0.752\n",
      "Neighborhood algorithm: LogisticRegression, parameters: [6.582261679757857, 'l2']\n",
      "scores=0.821\n",
      "Neighborhood algorithm: GaussianNB, parameters: [6.582261679757857, 'l2']\n",
      "scores=0.8470000000000001\n",
      "Neighborhood algorithm: SVC, parameters: [8.693961606814833, 0.24186886229050988]\n",
      "scores=0.9200000000000002\n",
      "Neighborhood algorithm: RandomForestClassifier, parameters: [14, 7]\n",
      "scores=0.914\n",
      "Neighborhood algorithm: LogisticRegression, parameters: [6.570217140062156, 'l2']\n",
      "scores=0.821\n",
      "Neighborhood algorithm: GradientBoostingClassifier, parameters: [25, 0.13248347230076618]\n",
      "scores=0.907\n",
      "Neighborhood algorithm: SVC, parameters: [4.485698366767023, 0.10089733862166073]\n",
      "scores=0.931\n",
      "Neighborhood algorithm: RandomForestClassifier, parameters: [44, 19]\n",
      "scores=0.929\n",
      "Neighborhood algorithm: MLPClassifier, parameters: [0.04350748468399812, 0.07782309003083655]\n",
      "scores=0.9350000000000002\n",
      "Neighborhood algorithm: GradientBoostingClassifier, parameters: [24, 0.16071404590567634]\n",
      "scores=0.906\n",
      "Neighborhood algorithm: DecisionTreeClassifier, parameters: [15, 8]\n",
      "scores=0.906\n",
      "Neighborhood algorithm: GaussianNB, parameters: [15, 8]\n",
      "scores=0.8470000000000001\n",
      "Neighborhood algorithm: MLPClassifier, parameters: [0.07393915403002739, 0.04244024213155017]\n",
      "scores=0.9369999999999999\n",
      "Neighborhood algorithm: GradientBoostingClassifier, parameters: [74, 0.13291365460715324]\n",
      "scores=0.9200000000000002\n",
      "Neighborhood algorithm: SVC, parameters: [9.816719542836397, 0.5996964545721807]\n",
      "scores=0.884\n",
      "Neighborhood algorithm: DecisionTreeClassifier, parameters: [4, 7]\n",
      "scores=0.884\n",
      "Neighborhood algorithm: LogisticRegression, parameters: [4.636783535277599, 'l2']\n",
      "scores=0.821\n",
      "Neighborhood algorithm: LogisticRegression, parameters: [8.673127576494347, 'l2']\n",
      "scores=0.82\n",
      "Neighborhood algorithm: LogisticRegression, parameters: [4.4971729874622355, 'l2']\n",
      "scores=0.821\n",
      "Neighborhood algorithm: GradientBoostingClassifier, parameters: [12, 0.1881057785693719]\n",
      "scores=0.9\n",
      "Neighborhood algorithm: GaussianNB, parameters: [12, 0.1881057785693719]\n",
      "scores=0.8470000000000001\n",
      "Neighborhood algorithm: MLPClassifier, parameters: [0.05166116134060702, 0.0476935108342396]\n",
      "scores=0.933\n",
      "Neighborhood algorithm: MLPClassifier, parameters: [0.05409786413340664, 0.06775452197361288]\n",
      "scores=0.925\n",
      "Neighborhood algorithm: RandomForestClassifier, parameters: [73, 13]\n",
      "scores=0.923\n",
      "Neighborhood algorithm: GradientBoostingClassifier, parameters: [75, 0.07774644269995017]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "\n",
    "class AutoML:\n",
    "    def __init__(self, initial_temp=100, cooling_rate=0.99, max_iterations=100, min_training_time=3600):\n",
    "        self.initial_temp = initial_temp\n",
    "        self.cooling_rate = cooling_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.min_training_time = max(min_training_time, 3600)\n",
    "\n",
    "        self.algorithms = {\n",
    "            'DecisionTreeClassifier': {\n",
    "                'class': DecisionTreeClassifier,\n",
    "                'parameters': ['max_depth', 'min_samples_split'],\n",
    "                'ranges': [(1, 20), (2, 20)]\n",
    "            },\n",
    "            'LogisticRegression': {\n",
    "                'class': LogisticRegression,\n",
    "                'parameters': ['C', 'penalty'],\n",
    "                'ranges': [(0.01, 10), ['l2', 'l1']]\n",
    "            },\n",
    "            'SVC': {\n",
    "                'class': SVC,\n",
    "                'parameters': ['C', 'gamma'],\n",
    "                'ranges': [(0.01, 10), (0.01, 1)]\n",
    "            },\n",
    "            'RandomForestClassifier': {\n",
    "                'class': RandomForestClassifier,\n",
    "                'parameters': ['n_estimators', 'max_depth'],\n",
    "                'ranges': [(10, 100), (1, 20)]\n",
    "            },\n",
    "            'GradientBoostingClassifier': {\n",
    "                'class': GradientBoostingClassifier,\n",
    "                'parameters': ['n_estimators', 'learning_rate'],\n",
    "                'ranges': [(10, 100), (0.01, 0.3)]\n",
    "            },\n",
    "            'MLPClassifier': {\n",
    "                'class': MLPClassifier,\n",
    "                'parameters': ['alpha', 'learning_rate_init'],\n",
    "                'ranges': [(0.0001, 0.1), (0.0001, 0.1)]\n",
    "            },\n",
    "            'GaussianNB': { \n",
    "                'class': GaussianNB,\n",
    "                'parameters': [],  \n",
    "                'ranges': []      \n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.best_solution = None\n",
    "        self.best_score = 0\n",
    "        self.model = None\n",
    "\n",
    "    def eval(self, model, X, y):\n",
    "        scores = cross_val_score(model, X, y, cv=5)\n",
    "        print('scores=' + str(np.mean(scores)))\n",
    "        return np.mean(scores)\n",
    "\n",
    "    def generate_neighborhood(self, current_solution):\n",
    "        new_solution = current_solution.copy()\n",
    "        algorithm_name = np.random.choice(list(self.algorithms.keys()))\n",
    "        new_solution[0] = algorithm_name\n",
    "\n",
    "        algorithm_info = self.algorithms[algorithm_name]\n",
    "        for i, parameter in enumerate(algorithm_info['parameters']):\n",
    "            if len(algorithm_info['ranges']) == 0:\n",
    "                return current_solution  \n",
    "\n",
    "            low, high = algorithm_info['ranges'][i]\n",
    "\n",
    "            if low is not None and high is not None:\n",
    "                if isinstance(high, list):  \n",
    "                    new_solution[i + 1] =  high\n",
    "                elif isinstance(high, str):  \n",
    "                    current_idx = algorithm_info['ranges'][i].index(high)\n",
    "                    new_idx = current_idx -1\n",
    "                   \n",
    "                    new_solution[i + 1] = algorithm_info['ranges'][i][new_idx]\n",
    "                elif isinstance(low, int) and isinstance(high, int): \n",
    "                    new_solution[i + 1] = np.random.randint(low, high)\n",
    "                else:  \n",
    "                    new_solution[i + 1] = np.random.uniform(low, high)\n",
    "\n",
    "        print(f\"Neighborhood algorithm: {algorithm_name}, parameters: {new_solution[1:]}\")\n",
    "        return new_solution\n",
    "\n",
    "    def create_model(self, solution):\n",
    "        algorithm_name = solution[0]\n",
    "        hyperparameters = solution[1:]\n",
    "        algorithm_class = self.algorithms[algorithm_name]['class']\n",
    "        if algorithm_name == 'LogisticRegression':\n",
    "            return algorithm_class(C=hyperparameters[0], penalty=hyperparameters[1], solver='liblinear')\n",
    "        elif algorithm_name == 'MLPClassifier':\n",
    "            return algorithm_class(alpha=hyperparameters[0], learning_rate_init=hyperparameters[1])\n",
    "        elif algorithm_name == 'GaussianNB':\n",
    "            return algorithm_class()  # No hyperparameters to pass for GaussianNB\n",
    "        else:\n",
    "            return algorithm_class(**{param: int(value) if param in ['max_depth', 'n_estimators', 'min_samples_split'] else value for param, value in zip(self.algorithms[algorithm_name]['parameters'], hyperparameters)})\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.simulated_annealing()\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been fit yet. Please call the fit method first.\")\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def simulated_annealing(self):\n",
    "        start_time = time.time()  # Track the start time of the process\n",
    "        \n",
    "        current_model = [np.random.choice(list(self.algorithms.keys()))]\n",
    "        if current_model[0] == 'RandomForestClassifier' or current_model[0] == 'DecisionTreeClassifier':\n",
    "            current_hyperparameters = [\n",
    "                np.random.randint(*self.algorithms[current_model[0]]['ranges'][i])\n",
    "                if self.algorithms[current_model[0]]['parameters'][i] in ['n_estimators', 'max_depth', 'min_samples_split']\n",
    "                else np.random.uniform(*self.algorithms[current_model[0]]['ranges'][i])\n",
    "                for i in range(len(self.algorithms[current_model[0]]['parameters']))\n",
    "            ]\n",
    "        elif current_model[0] == 'GradientBoostingClassifier':\n",
    "            current_hyperparameters = [\n",
    "                np.random.randint(*self.algorithms[current_model[0]]['ranges'][i]) if self.algorithms[current_model[0]]['parameters'][i] in ['n_estimators']\n",
    "                else np.random.uniform(*self.algorithms[current_model[0]]['ranges'][i])\n",
    "                for i in range(len(self.algorithms[current_model[0]]['parameters']))\n",
    "            ]\n",
    "        elif current_model[0] == 'SVC':\n",
    "            current_hyperparameters = [\n",
    "                np.random.uniform(*self.algorithms[current_model[0]]['ranges'][i]) if self.algorithms[current_model[0]]['parameters'][i] != 'penalty'\n",
    "                else np.random.choice(self.algorithms[current_model[0]]['ranges'][i])\n",
    "                for i in range(len(self.algorithms[current_model[0]]['parameters']))\n",
    "            ]\n",
    "        elif current_model[0] == 'LogisticRegression':\n",
    "            current_hyperparameters = [\n",
    "                np.random.uniform(*self.algorithms[current_model[0]]['ranges'][i])\n",
    "                if self.algorithms[current_model[0]]['parameters'][i] != 'penalty'\n",
    "                else np.random.choice(self.algorithms[current_model[0]]['ranges'][i])\n",
    "                for i in range(len(self.algorithms[current_model[0]]['parameters']))\n",
    "            ]\n",
    "        elif current_model[0] == 'GaussianNB':  # No hyperparameters to generate for GaussianNB\n",
    "            current_hyperparameters = []\n",
    "        else:\n",
    "            current_hyperparameters = [\n",
    "                np.random.uniform(*self.algorithms[current_model[0]]['ranges'][i])\n",
    "                for i in range(len(self.algorithms[current_model[0]]['parameters']))\n",
    "            ]\n",
    "    \n",
    "        current_solution = current_model + current_hyperparameters\n",
    "    \n",
    "        print(f\"Initial model: {current_model[0]}\")\n",
    "        print(f\"Initial parameters: {current_hyperparameters}\")\n",
    "    \n",
    "        current_score = self.eval(self.create_model(current_solution), self.X, self.y)\n",
    "        best_solution = current_solution\n",
    "        best_score = current_score\n",
    "    \n",
    "        temperature = self.initial_temp\n",
    "    \n",
    "        while time.time() - start_time < self.min_training_time:\n",
    "            for _ in range(100):\n",
    "                new_solution = self.generate_neighborhood(current_solution)\n",
    "                new_score = self.eval(self.create_model(new_solution), self.X, self.y)\n",
    "    \n",
    "                if new_score > current_score:\n",
    "                    current_solution = new_solution\n",
    "                    current_score = new_score\n",
    "                    if new_score > best_score:\n",
    "                        best_solution = new_solution\n",
    "                        best_score = new_score\n",
    "                else:\n",
    "                    acceptance_probability = np.exp((new_score - current_score) / temperature)\n",
    "                    if np.random.rand() < acceptance_probability:\n",
    "                        current_solution = new_solution\n",
    "                        current_score = new_score\n",
    "    \n",
    "            temperature *= self.cooling_rate\n",
    "    \n",
    "        self.best_solution = best_solution\n",
    "        self.best_score = best_score\n",
    "        self.model = self.create_model(best_solution)\n",
    "\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=42)\n",
    "automl = AutoML(min_training_time=3600)  # Set minimum training time to 1 hour\n",
    "automl.fit(X, y)\n",
    "predictions = automl.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f089b35-1988-4edd-bb7d-22bc2baad9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

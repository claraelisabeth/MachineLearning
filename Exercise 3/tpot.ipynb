{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT\n",
    "\n",
    "Group 18 Members:\n",
    "\n",
    "- Clara Pichler, 11917694\n",
    "- Hannah Knapp, 11901857 \n",
    "- Sibel Toprakkiran, 09426341\n",
    "\n",
    "### Overview\n",
    "\n",
    "1. Data Sets\n",
    "\n",
    "2. Evaluation of TPOT\n",
    "\n",
    "\n",
    "The evaluation our implementation and auto-sklearn will be done in the files `ML_A3_Group18.ipynb` and `auto_sklearn.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor, TPOTClassifier\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_data = pd.DataFrame(data= np.c_[iris['data'], iris['target']], columns= iris['feature_names'] + ['target'])\n",
    "iris_data['target'] = iris_data['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "df_voting = pd.read_csv('data/CongressionalVotingID.shuf.lrn.csv')\n",
    "\n",
    "df_airfoil = pd.read_csv(\"data/airfoil_noise_data.csv\")\n",
    "\n",
    "url='./data/abalone.csv'\n",
    "column_names = [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole_weight\", \"Shucked_weight\", \"Viscera_weight\", \"Shell_weight\", \"Rings\"]\n",
    "df_abalone = pd.read_csv(url, header=0, names=column_names)\n",
    "df_abalone = df_abalone[df_abalone.Height != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarapichler/Documents/Projects/myenv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "df_voting = df_voting.replace({\"democrat\": 0,\"republican\": 1,\"n\": 0,\"y\": 1,\"unknown\": np.nan})\n",
    "df_voting = df_voting.drop(columns=['ID'])\n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "df_voting = pd.DataFrame(imp.fit_transform(df_voting), columns=df_voting.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abalone = df_abalone[df_abalone.Height != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris = iris_data.drop(['target'], axis=1)\n",
    "y_iris = iris_data['target']\n",
    "\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris, y_iris, test_size=0.70, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_voting = df_voting.drop(['class'], axis=1)\n",
    "y_voting = df_voting['class']\n",
    "\n",
    "X_train_voting, X_test_voting, y_train_voting, y_test_voting = train_test_split(X_voting, y_voting, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_airfoil = df_airfoil.drop(['y'], axis=1)\n",
    "y_airfoil = df_airfoil['y']\n",
    "\n",
    "X_train_airfoil, X_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split(X_airfoil, y_airfoil, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_abalone_reg = df_abalone.drop(['Rings'], axis=1)\n",
    "y_abalone_reg = df_abalone['Rings']\n",
    "\n",
    "X_train_abalone_reg, X_test_abalone_reg, y_train_abalone_reg, y_test_abalone_reg = train_test_split(X_abalone_reg, y_abalone_reg, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_abalone_class = df_abalone.drop(['Sex'], axis=1)\n",
    "y_abalone_class = df_abalone['Sex']\n",
    "\n",
    "X_train_abalone_class, X_test_abalone_class, y_train_abalone_class, y_test_abalone_class = train_test_split(X_abalone_class, y_abalone_class, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TPOTClassifier(verbosity=2, population_size=50, generations=10, random_state=35)\n",
    " \n",
    "def fit_eval_class(X_train, y_train, X_test, y_test, name):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    #test_mse = mean_squared_error(y_test, predictions)\n",
    "    #test_rmse = np.sqrt(test_mse)  \n",
    "    #test_mae = mean_absolute_error(y_test, predictions)\n",
    "    #test_r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    #print(f\"Test MSE: {test_mse:.4f}\")\n",
    "    #print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "    #print(f\"Test MAE: {test_mae:.4f}\")\n",
    "    #print(f\"Test R^2: {test_r2:.4f}\")\n",
    "    #reg.export('tpot_'+ name +'.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = TPOTRegressor(verbosity=2, population_size=50, generations=10, random_state=35)\n",
    " \n",
    "def fit_eval_reg(X_train, y_train, X_test, y_test, name):\n",
    "    reg.fit(X_train, y_train)\n",
    "    #test_mse = mean_squared_error(y_test, predictions)\n",
    "    #test_rmse = np.sqrt(test_mse)  \n",
    "    #test_mae = mean_absolute_error(y_test, predictions)\n",
    "    #test_r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    #print(f\"Test MSE: {test_mse:.4f}\")\n",
    "    #print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "    #print(f\"Test MAE: {test_mae:.4f}\")\n",
    "    #print(f\"Test R^2: {test_r2:.4f}\")\n",
    "    #reg.export('tpot_'+ name +'.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2feae209605482c824ea234fc3ffd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/550 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 1.0\n",
      "\n",
      "Generation 2 - Current best internal CV score: 1.0\n",
      "\n",
      "Generation 3 - Current best internal CV score: 1.0\n",
      "\n",
      "Generation 4 - Current best internal CV score: 1.0\n",
      "\n",
      "Generation 5 - Current best internal CV score: 1.0\n",
      "\n",
      "Generation 6 - Current best internal CV score: 1.0\n",
      "\n",
      "Generation 7 - Current best internal CV score: 1.0\n",
      "\n",
      "Generation 8 - Current best internal CV score: 1.0\n",
      "\n",
      "Generation 9 - Current best internal CV score: 1.0\n",
      "\n",
      "Generation 10 - Current best internal CV score: 1.0\n",
      "\n",
      "Best pipeline: MLPClassifier(input_matrix, alpha=0.001, learning_rate_init=0.01)\n"
     ]
    }
   ],
   "source": [
    "fit_eval_class(X_train_iris, y_train_iris, X_test_iris, y_test_iris, 'iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

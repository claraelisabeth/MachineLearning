{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dca6400-b525-4d15-9639-3471192f9d3c",
   "metadata": {},
   "source": [
    "# Implementation of Simulated Annealing\n",
    "\n",
    "## Initial Model\n",
    "We will start with 0-Rule model, which is a simple baseline classification model. It does not use any features for prediction but instead predicts the most frequent class (mode) in the training dataset. This can serve as a baseline to compare the performance of more sophisticated models.\n",
    "\n",
    "## Temparature\n",
    "We use the temperature to escape local maximums, we sometimes accept bad values but we gradually decrease the frequency of accepting bad values.\n",
    "\n",
    "if eval(vc ) < eval(vn ) then vc = vn -> possibility of accepting a state with a better outcome is always 1.\n",
    "else calculate the acceptance probability is  np.exp((new_score - current_score) / temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b76998-1885-456f-833d-ef2a8474029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class AutoML:\n",
    "    def __init__(self, initial_temp=100, cooling_rate=0.99, max_iterations=100, min_training_time=3600):\n",
    "        self.initial_temp = initial_temp\n",
    "        self.cooling_rate = cooling_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.min_training_time = min_training_time\n",
    "\n",
    "        self.algorithms = {\n",
    "            'DecisionTreeClassifier': {\n",
    "                'class': DecisionTreeClassifier,\n",
    "                'parameters': ['max_depth', 'min_samples_split'],\n",
    "                'ranges': [(1, 20), (2, 20)]\n",
    "            },\n",
    "            'SVC': {\n",
    "                'class': SVC,\n",
    "                'parameters': ['C', 'gamma'],\n",
    "                'ranges': [(0.01, 10), (0.01, 1)]\n",
    "            },\n",
    "            'RandomForestClassifier': {\n",
    "                'class': RandomForestClassifier,\n",
    "                'parameters': ['n_estimators', 'max_depth'],\n",
    "                'ranges': [(10, 100), (1, 20)]\n",
    "            },\n",
    "            'GradientBoostingClassifier': {\n",
    "                'class': GradientBoostingClassifier,\n",
    "                'parameters': ['n_estimators', 'learning_rate'],\n",
    "                'ranges': [(10, 100), (0.01, 0.3)]\n",
    "            },\n",
    "            'MLPClassifier': {\n",
    "                'class': MLPClassifier,\n",
    "                'parameters': ['alpha', 'learning_rate_init'],\n",
    "                'ranges': [(0.0001, 0.1), (0.0001, 0.1)]\n",
    "            },\n",
    "            'GaussianNB': { \n",
    "                'class': GaussianNB,\n",
    "                'parameters': [],  \n",
    "                'ranges': []      \n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.best_solution = None\n",
    "        self.best_score = 0\n",
    "        self.model = None\n",
    "\n",
    "    def eval(self, model, X, y):\n",
    "        model.fit(X, y) \n",
    "        predictions = model.predict(X)  \n",
    "        accuracy = np.mean(predictions == y)  \n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "        return accuracy\n",
    "        \n",
    "    def generate_neighborhood_withsmallchanges(self, current_solution):\n",
    "        algorithm_name = current_solution[0]\n",
    "        algorithm_info = self.algorithms[algorithm_name]\n",
    "        new_solution = current_solution[:]\n",
    "    \n",
    "        if not algorithm_info['parameters']:\n",
    "            new_solution[0] = np.random.choice(list(self.algorithms.keys()))\n",
    "            return new_solution\n",
    "    \n",
    "        while len(new_solution) < len(algorithm_info['parameters']) + 1:\n",
    "            new_solution.append(None)\n",
    "    \n",
    "        param_idx = np.random.randint(1, len(new_solution))\n",
    "        low, high = algorithm_info['ranges'][param_idx - 1]\n",
    "    \n",
    "        if isinstance(low, int) and isinstance(high, int):\n",
    "            new_solution[param_idx] = np.random.randint(low, high)\n",
    "        elif isinstance(low, float) and isinstance(high, float):\n",
    "            new_solution[param_idx] = np.random.uniform(low, high)\n",
    "    \n",
    "        if np.random.rand() < 0.1:\n",
    "            new_solution[0] = np.random.choice(list(self.algorithms.keys()))\n",
    "            algorithm_info = self.algorithms[new_solution[0]]\n",
    "            new_solution = [new_solution[0]] + [\n",
    "                np.random.uniform(low, high) if isinstance(low, float) and isinstance(high, float)\n",
    "                else np.random.randint(low, high)\n",
    "                for low, high in algorithm_info['ranges']\n",
    "            ]\n",
    "    \n",
    "        print(f\"Generated neighborhood for algorithm: {new_solution[0]}, parameters: {new_solution[1:]}\")\n",
    "        return new_solution\n",
    "\n",
    "\n",
    "        \n",
    "    def generate_neighborhood(self, current_solution):\n",
    "        if not isinstance(current_solution, list):\n",
    "            current_solution = [current_solution.__class__.__name__]\n",
    "    \n",
    "        algorithm_name = np.random.choice(list(self.algorithms.keys()))\n",
    "        algorithm_info = self.algorithms[algorithm_name]\n",
    "    \n",
    "        new_solution = [algorithm_name] + [None] * len(algorithm_info['parameters'])\n",
    "    \n",
    "        for i, parameter in enumerate(algorithm_info['parameters']):\n",
    "            if len(algorithm_info['ranges']) == 0:\n",
    "                continue \n",
    "    \n",
    "            low, high = algorithm_info['ranges'][i]\n",
    "    \n",
    "            if low is not None and high is not None:\n",
    "                if isinstance(high, list):  \n",
    "                    new_solution[i + 1] = np.random.choice(high)\n",
    "                elif isinstance(high, str):  \n",
    "                    current_idx = algorithm_info['ranges'][i].index(high)\n",
    "                    new_idx = (current_idx - 1) % len(algorithm_info['ranges'][i])\n",
    "                    new_solution[i + 1] = algorithm_info['ranges'][i][new_idx]\n",
    "                elif isinstance(low, int) and isinstance(high, int): \n",
    "                    new_solution[i + 1] = np.random.randint(low, high)\n",
    "                else:  \n",
    "                    new_solution[i + 1] = np.random.uniform(low, high)\n",
    "    \n",
    "        print(f\"Neighborhood algorithm: {algorithm_name}, parameters: {new_solution[1:]}\")\n",
    "        return new_solution\n",
    "\n",
    "    def create_model(self, solution):\n",
    "        algorithm_name = solution[0]\n",
    "        hyperparameters = solution[1:]\n",
    "        algorithm_info = self.algorithms[algorithm_name]\n",
    "        algorithm_class = algorithm_info['class']\n",
    "    \n",
    "        if algorithm_name == 'MLPClassifier':\n",
    "            alpha = hyperparameters[0] if len(hyperparameters) > 0 else 0.0001\n",
    "            learning_rate_init = hyperparameters[1] if len(hyperparameters) > 1 else 0.001\n",
    "            return algorithm_class(alpha=alpha, learning_rate_init=learning_rate_init)\n",
    "        elif algorithm_name == 'GaussianNB':\n",
    "            return algorithm_class()\n",
    "    \n",
    "        valid_params = {\n",
    "            param: int(value) if param in ['max_depth', 'n_estimators', 'min_samples_split'] else value\n",
    "            for param, value in zip(algorithm_info['parameters'], hyperparameters)\n",
    "            if value is not None\n",
    "        }\n",
    "        return algorithm_class(**valid_params)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.simulated_annealing()\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"The model has not been fit yet. Please call the fit method first.\")\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def simulated_annealing(self):\n",
    "        start_time = time.time()  \n",
    "        # 0 rule model as initial model as base model\n",
    "        zero_r_model = DummyClassifier(strategy='most_frequent')\n",
    "        #zero_r_model.fit(self.X, self.y) \n",
    "\n",
    "        print(f\"Initial model: DummyClassifier\")\n",
    "        print(f\"Initial parameters: (strategy='most_frequent')\")\n",
    "\n",
    "        current_solution = ['DummyClassifier']\n",
    "        current_score = self.eval(zero_r_model, self.X, self.y)\n",
    "        best_solution = current_solution\n",
    "        best_score = current_score\n",
    "    \n",
    "        temperature = self.initial_temp\n",
    "    \n",
    "        while time.time() - start_time < self.min_training_time:\n",
    "            for i in range(100):\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Iteration {i}, Temperature {temperature:.3f}, Best Evaluation {best_score:.5f}\")\n",
    "                    \n",
    "                if current_solution[0] == 'DummyClassifier':\n",
    "                    new_solution = self.generate_neighborhood(['DecisionTreeClassifier'])\n",
    "                    new_score = self.eval(self.create_model(new_solution), self.X, self.y)\n",
    "                else:\n",
    "                    new_solution = self.generate_neighborhood_withsmallchanges(current_solution)\n",
    "                    new_score = self.eval(self.create_model(new_solution), self.X, self.y)\n",
    "    \n",
    "                if new_score > current_score:\n",
    "                    current_solution = new_solution\n",
    "                    current_score = new_score\n",
    "                    if new_score > best_score:\n",
    "                        best_solution = new_solution\n",
    "                        best_score = new_score\n",
    "                else:\n",
    "                    acceptance_probability = np.exp((new_score - current_score) / temperature)\n",
    "                    if np.random.rand() < acceptance_probability:\n",
    "                        current_solution = new_solution\n",
    "                        current_score = new_score\n",
    "    \n",
    "            temperature *= self.cooling_rate\n",
    "    \n",
    "        self.best_solution = best_solution\n",
    "        self.best_score = best_score\n",
    "        self.model = self.create_model(best_solution)\n",
    "        self.model.fit(self.X, self.y)\n",
    "        print(f'best_score is {best_score}')\n",
    "        print(f'best_solution is {best_solution}')\n",
    "#X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8fb4826-d38b-4a4b-8b18-e58f8e993fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Rings_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Rings  Sex_F  Sex_I  Sex_M  Rings_Category  \n",
       "0         0.150     15      0      0      1               2  \n",
       "1         0.070      7      0      0      1               0  \n",
       "2         0.210      9      1      0      0               1  \n",
       "3         0.155     10      0      0      1               1  \n",
       "4         0.055      7      0      1      0               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4175 entries, 0 to 4176\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Length          4175 non-null   float64\n",
      " 1   Diameter        4175 non-null   float64\n",
      " 2   Height          4175 non-null   float64\n",
      " 3   Whole_weight    4175 non-null   float64\n",
      " 4   Shucked_weight  4175 non-null   float64\n",
      " 5   Viscera_weight  4175 non-null   float64\n",
      " 6   Shell_weight    4175 non-null   float64\n",
      " 7   Rings           4175 non-null   int64  \n",
      " 8   Sex_F           4175 non-null   uint8  \n",
      " 9   Sex_I           4175 non-null   uint8  \n",
      " 10  Sex_M           4175 non-null   uint8  \n",
      " 11  Rings_Category  4175 non-null   int64  \n",
      "dtypes: float64(7), int64(2), uint8(3)\n",
      "memory usage: 338.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_names = [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole_weight\", \"Shucked_weight\", \"Viscera_weight\", \"Shell_weight\", \"Rings\"]\n",
    "df_abalone = pd.read_csv(\"./data/abalone.csv\", header=0, names=column_names)\n",
    "df_abalone[df_abalone.Height == 0]\n",
    "df_abalone = df_abalone[df_abalone.Height != 0]\n",
    "df_abalone = pd.get_dummies(df_abalone, columns=['Sex'], drop_first=False)\n",
    "\n",
    "def categorize_rings(rings):\n",
    "    if rings < 8:\n",
    "        return 0\n",
    "    elif rings <= 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df_abalone['Rings_Category'] = df_abalone['Rings'].apply(categorize_rings)\n",
    "\n",
    "display(df_abalone.head())\n",
    "display(df_abalone.info())\n",
    "X = df_abalone.drop(\"Rings\", axis=1).values\n",
    "y = df_abalone[\"Rings\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef7e869-823f-467b-bbbb-b4ed4cd6a1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model: DummyClassifier\n",
      "Initial parameters: (strategy='most_frequent')\n",
      "Accuracy: 0.1667\n",
      "Iteration 0, Temperature 100.000, Best Evaluation 0.16672\n",
      "Neighborhood algorithm: DecisionTreeClassifier, parameters: [1, 15]\n",
      "Accuracy: 0.2558\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [6, 15]\n",
      "Accuracy: 0.4449\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [6, 15]\n",
      "Accuracy: 0.4449\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [6, 12]\n",
      "Accuracy: 0.4462\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [6, 16]\n",
      "Accuracy: 0.4449\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [6, 4]\n",
      "Accuracy: 0.4481\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [6, 4]\n",
      "Accuracy: 0.4481\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [6, 2]\n",
      "Accuracy: 0.4484\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 2]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [18, 2]\n",
      "Accuracy: 0.9515\n",
      "Iteration 10, Temperature 100.000, Best Evaluation 0.95145\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [9, 2]\n",
      "Accuracy: 0.5586\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [9, 9]\n",
      "Accuracy: 0.5385\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [3, 9]\n",
      "Accuracy: 0.3721\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [3, 14]\n",
      "Accuracy: 0.3721\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 14]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 14]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 10]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 7]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 4]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 10]\n",
      "Accuracy: 0.3996\n",
      "Iteration 20, Temperature 100.000, Best Evaluation 0.95145\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 16]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 6]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [13, 6]\n",
      "Accuracy: 0.7253\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [16, 6]\n",
      "Accuracy: 0.7962\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [16, 9]\n",
      "Accuracy: 0.7429\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [16, 9]\n",
      "Accuracy: 0.7445\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [16, 4]\n",
      "Accuracy: 0.8438\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [6, 4]\n",
      "Accuracy: 0.4481\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [18, 4]\n",
      "Accuracy: 0.8735\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [19, 4]\n",
      "Accuracy: 0.8809\n",
      "Iteration 30, Temperature 100.000, Best Evaluation 0.95145\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [19, 17]\n",
      "Accuracy: 0.6599\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [2, 3]\n",
      "Accuracy: 0.3200\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [9, 3]\n",
      "Accuracy: 0.5561\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [11, 3]\n",
      "Accuracy: 0.6615\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [11, 13]\n",
      "Accuracy: 0.6040\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [12, 13]\n",
      "Accuracy: 0.6308\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [13, 13]\n",
      "Accuracy: 0.6535\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [8, 13]\n",
      "Accuracy: 0.5037\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [8, 14]\n",
      "Accuracy: 0.5018\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 14]\n",
      "Accuracy: 0.3996\n",
      "Iteration 40, Temperature 100.000, Best Evaluation 0.95145\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [15, 14]\n",
      "Accuracy: 0.6768\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [15, 6]\n",
      "Accuracy: 0.7796\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [15, 10]\n",
      "Accuracy: 0.7154\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [10, 10]\n",
      "Accuracy: 0.5771\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [9, 10]\n",
      "Accuracy: 0.5363\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [8, 10]\n",
      "Accuracy: 0.5072\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [18, 10]\n",
      "Accuracy: 0.7355\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [19, 10]\n",
      "Accuracy: 0.7349\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.00202193058449803, 0.0665617728703809]\n",
      "Accuracy: 0.3871\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.00202193058449803, 0.07190841282840187]\n",
      "Accuracy: 0.3829\n",
      "Iteration 50, Temperature 100.000, Best Evaluation 0.95145\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.00202193058449803, 0.05410819691398487]\n",
      "Accuracy: 0.3960\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.00202193058449803, 0.04924403821128952]\n",
      "Accuracy: 0.3973\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.06769581550011848, 0.04924403821128952]\n",
      "Accuracy: 0.3740\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.0737478708396506, 0.04924403821128952]\n",
      "Accuracy: 0.3897\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.014557372418345737, 0.04924403821128952]\n",
      "Accuracy: 0.3903\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.016646544931397198, 0.04924403821128952]\n",
      "Accuracy: 0.3912\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.04930467555610184, 0.04924403821128952]\n",
      "Accuracy: 0.3599\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.04930467555610184, 0.09295885446339253]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sibeltoprakkiran/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3782\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.04930467555610184, 0.030871487367649397]\n",
      "Accuracy: 0.3906\n",
      "Generated neighborhood for algorithm: MLPClassifier, parameters: [0.08452080378847067, 0.030871487367649397]\n",
      "Accuracy: 0.3858\n",
      "Iteration 60, Temperature 100.000, Best Evaluation 0.95145\n",
      "Generated neighborhood for algorithm: GaussianNB, parameters: []\n",
      "Accuracy: 0.3229\n",
      "Accuracy: 1.0000\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, None]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [4, 8]\n",
      "Accuracy: 0.3996\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [6, 8]\n",
      "Accuracy: 0.4478\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [19, 8]\n",
      "Accuracy: 0.7752\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [19, 15]\n",
      "Accuracy: 0.6765\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [7, 15]\n",
      "Accuracy: 0.4714\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [3, 15]\n",
      "Accuracy: 0.3721\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [10, 15]\n",
      "Accuracy: 0.5644\n",
      "Iteration 70, Temperature 100.000, Best Evaluation 1.00000\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [14, 15]\n",
      "Accuracy: 0.6576\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [14, 9]\n",
      "Accuracy: 0.7135\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [14, 8]\n",
      "Accuracy: 0.7250\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [10, 8]\n",
      "Accuracy: 0.5902\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [13, 8]\n",
      "Accuracy: 0.7017\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [16, 8]\n",
      "Accuracy: 0.7579\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [16, 18]\n",
      "Accuracy: 0.6461\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [16, 17]\n",
      "Accuracy: 0.6541\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [19, 17]\n",
      "Accuracy: 0.6602\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [18, 17]\n",
      "Accuracy: 0.6592\n",
      "Iteration 80, Temperature 100.000, Best Evaluation 1.00000\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [18, 13]\n",
      "Accuracy: 0.6937\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [18, 8]\n",
      "Accuracy: 0.7726\n",
      "Generated neighborhood for algorithm: DecisionTreeClassifier, parameters: [18, 17]\n",
      "Accuracy: 0.6595\n",
      "Generated neighborhood for algorithm: SVC, parameters: [3, 0]\n",
      "Accuracy: 0.1667\n",
      "Generated neighborhood for algorithm: SVC, parameters: [3, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m automl \u001b[38;5;241m=\u001b[39m AutoML(min_training_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \n\u001b[0;32m----> 4\u001b[0m automl\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[0;32mIn[15], line 153\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulated_annealing()\n",
      "Cell \u001b[0;32mIn[15], line 186\u001b[0m, in \u001b[0;36mAutoML.simulated_annealing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     new_solution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_neighborhood_withsmallchanges(current_solution)\n\u001b[0;32m--> 186\u001b[0m     new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_model(new_solution), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_score \u001b[38;5;241m>\u001b[39m current_score:\n\u001b[1;32m    189\u001b[0m     current_solution \u001b[38;5;241m=\u001b[39m new_solution\n",
      "Cell \u001b[0;32mIn[15], line 61\u001b[0m, in \u001b[0;36mAutoML.eval\u001b[0;34m(self, model, X, y)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, X, y):\n\u001b[1;32m     60\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X, y) \n\u001b[0;32m---> 61\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)  \n\u001b[1;32m     62\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(predictions \u001b[38;5;241m==\u001b[39m y)  \n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:813\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    811\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 813\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:430\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    428\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[1;32m    429\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:449\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    442\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be equal to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of samples at training time\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    445\u001b[0m         )\n\u001b[1;32m    447\u001b[0m svm_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m libsvm\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    450\u001b[0m     X,\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dual_coef_,\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intercept_,\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    458\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msvm_type,\n\u001b[1;32m    459\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[1;32m    460\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[1;32m    461\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[1;32m    462\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[1;32m    463\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[1;32m    464\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "automl = AutoML(min_training_time=10) \n",
    "automl.fit(X_train, y_train)\n",
    "predictions = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee289f06-93d8-4130-b573-b5fb54d042f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

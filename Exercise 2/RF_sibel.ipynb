{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab503f22-21ed-46ac-934d-e57dc1316122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8d837f84-65ca-4f09-91b6-f609a85b601f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_Width</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_Width    type\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa\n",
       "5           5.4          3.9           1.7          0.4  Setosa\n",
       "6           4.6          3.4           1.4          0.3  Setosa\n",
       "7           5.0          3.4           1.5          0.2  Setosa\n",
       "8           4.4          2.9           1.4          0.2  Setosa\n",
       "9           4.9          3.1           1.5          0.1  Setosa"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['sepal_length', 'sepal_width', 'petal_length','petal_Width','type']\n",
    "data = pd.read_csv('./data/iris.csv',skiprows=1, header=None, names=col_names)\n",
    "data_classification.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c795f32b-04c5-493b-9d59-f29b2362fe23",
   "metadata": {},
   "source": [
    "# Decison "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b607f-a942-432c-8301-c1fc3cc0dbcc",
   "metadata": {},
   "source": [
    "In a decision tree, there are two ypes of nodes, decision nodes and leaf nodes. In leaf nodes we try to have pure classes. In decision nodes we do decide if we go to the left or right tree depending on the condition feature selection algorithm we choose (feature_index and threshold for this feature). We try to maximize the information gain with each split. \n",
    "It is a greddy search algortihm, so we try on each solit to mazimeze the decision but don't go back."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02802b73-7e3e-4408-8b37-a5451d05ec92",
   "metadata": {},
   "source": [
    "## Classification Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61cf660-e9d6-404e-b266-28b7f5aae92e",
   "metadata": {},
   "source": [
    "The tree class for classification problems: (we will not submit this is only for me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6724fafa-c17e-4cfb-80a3-2930ed8324e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, leftChild=None, rightChild=None, info_gain=None, value=None):\n",
    "\n",
    "        self.feature_index = feature_index\n",
    "        self.leftChild = leftChild\n",
    "        self.rightChild = rightChild\n",
    "        self.info_gain = info_gain\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4953e9b3-5ff6-466b-97e9-cdf466244f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "\n",
    "        self.root = None\n",
    "\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "        else:\n",
    "            print(\"X_\"+ str(tree.feature_index), \"<=\", tree.threshold, \"? info_gain: \", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.leftChild, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.rightChild, indent + indent)\n",
    "            \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        train,test = dataset[:,:-1], dataset[:,-1]\n",
    "\n",
    "        num_samples, num_features = np.shape(train)\n",
    "\n",
    "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            if best_split[\"infoGain\"] > 0:\n",
    "                leftTree = self.build_tree(best_split['dataset_left'], curr_depth+1)\n",
    "                rightTree = self.build_tree(best_split['dataset_right'], curr_depth+1)\n",
    "                return Node(best_split['feature_index'], best_split['threshold'],\n",
    "                           leftTree, rightTree, best_split['infoGain'])\n",
    "\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "\n",
    "        best_split={}\n",
    "        max_info_gain=-float(\"inf\")\n",
    "\n",
    "        # loop over all features\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values=dataset[:, feature_index]\n",
    "            possible_featurevalues=np.unique(feature_values)\n",
    "\n",
    "            for threshold in possible_featurevalues:\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                    y, left_y, right_y = dataset[:,-1], dataset_left[:,-1], dataset_right[:,-1]\n",
    "                    curr_info_gain=self.information_gain(y, left_y,right_y,\"gini\")\n",
    "                    if curr_info_gain > max_info_gain:\n",
    "                        best_split['feature_index'] = feature_index\n",
    "                        best_split['threshold'] = threshold\n",
    "                        best_split['infoGain'] = curr_info_gain\n",
    "                        best_split['dataset_left'] = dataset_left\n",
    "                        best_split['dataset_right'] = dataset_right\n",
    "                        max_info_gain=curr_info_gain\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child, mode='entrophy'):\n",
    "        weigth_l = len(l_child)/len(parent)\n",
    "        weigth_r = len(r_child)/len(parent)\n",
    "        if mode=='gini':\n",
    "            gain = self.gini_index(parent) - (weigth_l *self.gini_index(l_child)- weigth_r *self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entrophy(parent) - (weigth_l *self.gini_index(l_child)- weigth_r *self.gini_index(r_child))\n",
    "        return gain\n",
    "\n",
    "\n",
    "    def entrophy(self, dataset, feature_index, threshold):\n",
    "        class_labels = np.unique(y)\n",
    "        entrophy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y==cls])/len(y)\n",
    "            entrophy += -p_cls - np.log1(p_cls)\n",
    "        return 1 - entrophy\n",
    "        \n",
    "    def gini_index(self, y):\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y==cls])/len(y)\n",
    "            gini += p_cls ** 2\n",
    "        return 1 - gini\n",
    "\n",
    "    def calculate_leaf_value(self, Y):\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "\n",
    "    def fit(self, X,Y):\n",
    "        dataset = np.concatenate((X,Y), axis = 1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def predict(self, x):\n",
    "        predictions = [self.make_prediction(x,self.root) for x in x]\n",
    "        return predictions\n",
    "\n",
    "    def make_prediction(self, x, tree):\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.leftChild)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.rightChild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f18e4e0a-208f-4564-a9a1-a4e968da46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_classification.iloc[:, :-1].values\n",
    "Y = data_classification.iloc[:, -1].values.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "66152e11-7e8e-49d1-a3a1-2e939e1da28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_0 <= 4.3 ? info_gain:  1.327592203548086\n",
      " left:['Setosa']\n",
      " right:X_2 <= 1.0 ? info_gain:  1.3276365381646178\n",
      "  left:['Setosa']\n",
      "  right:X_1 <= 2.0 ? info_gain:  1.3274908723055807\n",
      "    left:['Setosa']\n",
      "    right:X_1 <= 2.2 ? info_gain:  1.327145379753691\n",
      "        left:['Setosa']\n",
      "        right:['Setosa']\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "classifier.fit(X_train,Y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5f646e96-b4d2-4e0f-8255-d09a8a2704d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  0]\n",
      " [11  0  0]\n",
      " [10  0  0]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test) \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(Y_test, Y_pred)\n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b6df5-8bb5-4c7e-9a65-702734d11019",
   "metadata": {},
   "source": [
    "## Regression Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c71e217e-0f3a-46c1-bcae-c71b7138a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, currFeatureIndex=None, threshold=None, leftChild=None, rightChild=None, variance_reduction=None, value=None):\n",
    "\n",
    "        self.currFeatureIndex = currFeatureIndex\n",
    "        self.threshold = threshold\n",
    "        self.leftChild = leftChild\n",
    "        self.rightChild = rightChild\n",
    "        self.variance_reduction = variance_reduction\n",
    "\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd945934-7702-4aa8-b1d7-bc8615cd3c12",
   "metadata": {},
   "source": [
    "If it is a regression problem we use variance reduction as a measurement of impurity of a node. \n",
    "$\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\bar{y})^2$\n",
    "1. Calculate the difference between each data point yi and the mean y.\n",
    "2. Square each of these differences.\n",
    "3. Sum up all the squared differences.\n",
    "4. Divide the sum by the total number of data points n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "dfb89475-0da4-4f80-ac9f-45600db2fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "\n",
    "        self.root = None\n",
    "\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.currFeatureIndex), \"<=\", tree.threshold, \"?\", tree.variance_reduction)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.leftChild, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.rightChild, indent + indent)\n",
    "            \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        print('build_tree')\n",
    "        train,test = dataset[:,:-1], dataset[:,-1]\n",
    "\n",
    "        num_samples, num_features = np.shape(train)\n",
    "\n",
    "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
    "            \n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            print(best_split.keys)\n",
    "            if len(best_split) != 0 and best_split['variance_reduction'] > 0:\n",
    "                leftTree = self.build_tree(best_split['dataset_left'], curr_depth+1)\n",
    "                rightTree = self.build_tree(best_split['dataset_right'], curr_depth+1)\n",
    "                return Node(best_split['currFeatureIndex'], best_split['threshold'],\n",
    "                           leftTree, rightTree, best_split['variance_reduction'])\n",
    "\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def get_best_split(self, dataset, num_samples, num_features) -> dict:\n",
    "        print('get best split')\n",
    "        best_split={}\n",
    "        max_variance_reduction=-float(\"inf\")\n",
    "        # loop over all features\n",
    "        for currFeatureIndex in range(num_features):\n",
    "            print('num_features:' + str(num_features) + \" currFeatureIndex:\" + str(currFeatureIndex))    \n",
    "            feature_values=dataset[:, currFeatureIndex]\n",
    "            possible_featurevalues=np.unique(feature_values)\n",
    "\n",
    "            for threshold in possible_featurevalues:\n",
    "                dataset_left, dataset_right = self.split(dataset, currFeatureIndex, threshold)\n",
    "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                    print(best_split.keys())\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    curr_variance_reduction= self.variance_reduction(y, left_y, right_y)\n",
    "                    if curr_variance_reduction > max_variance_reduction:\n",
    "                        best_split['currFeatureIndex'] = currFeatureIndex\n",
    "                        best_split['threshold'] = threshold\n",
    "                        best_split['variance_reduction'] = curr_variance_reduction\n",
    "                        best_split['dataset_left'] = dataset_left\n",
    "                        best_split['dataset_right'] = dataset_right\n",
    "                        max_variance_reduction=curr_variance_reduction\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def split(self, dataset, currFeatureIndex, threshold):\n",
    "        dataset_left = np.array([row for row in dataset if row[currFeatureIndex]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[currFeatureIndex]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "\n",
    "    def variance_reduction(self, parent, l_child, r_child):        \n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        print(parent)\n",
    "        print(l_child)\n",
    "        print(r_child)\n",
    "        reduction = np.var(parent) - (weight_l * np.var(l_child) + weight_r * np.var(r_child))\n",
    "        return reduction\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        Y = np.mean(Y)\n",
    "        return Y\n",
    "\n",
    "    def fit(self, X,Y):\n",
    "        dataset = np.concatenate((X,Y), axis = 1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self.make_prediction(X,self.root) for X in X]\n",
    "        return predictions\n",
    "\n",
    "    def make_prediction(self, X, tree):\n",
    "        if tree.value != None:\n",
    "            return tree.value\n",
    "            \n",
    "        feature_val = X[tree.currFeatureIndex]\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(X, tree.leftChild)\n",
    "        else:\n",
    "            return self.make_prediction(X, tree.rightChild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "97728a67-7d1a-4ce3-a365-682200cfba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/airfoil_noise_data.csv\")\n",
    "data = data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "0a22dd37-7d77-43d4-9a71-ccbb5b95a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "c9402d49-9ba8-4124-89b8-1692a1b3ad9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 127.461 127.591 126.201]\n",
      "[126.201]\n",
      "[125.951 127.461 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[125.951 127.461 127.591 126.201]\n",
      "[125.951 126.201]\n",
      "[127.461 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[125.951 127.461 127.591 126.201]\n",
      "[125.951 127.591 126.201]\n",
      "[127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D8E940>\n",
      "build_tree\n",
      "build_tree\n",
      "X_0 <= 1250.0 ? 0.525625000000002\n",
      " left:126.481\n",
      " right:126.481\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(min_samples_split=3, max_depth=3)\n",
    "regressor.fit(X_train,Y_train)\n",
    "regressor.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d1d24-2967-455c-ae75-ffdc7cd6aa4c",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2649f1b-4555-4619-9000-60a339bb9cb7",
   "metadata": {},
   "source": [
    "It is a collection of randomly chosen decision trees. Build new datasets from our origninal dataset. Randomly select rows from the dataset. One row can occur more then 1 time. (bootstrapping)\n",
    "We also randomly select features. At the end we select the majority voting on the prediction (this is called aggregation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f492a3ea-36ee-4c30-9465-184f9501c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def bootstrap_sample(X,y):\n",
    "    n_samples = X.shape[0]\n",
    "    idxs=np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    return X[idxs],y[idxs]\n",
    "\n",
    "def most_common_label(y):\n",
    "    counter = Counter(y)\n",
    "    most_common = counter.most_common(1)[0][0]\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "aa05d682-93cf-414b-b433-195221efc12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest():\n",
    "    def __init__(self, num_trees = 15, max_depth = 15, min_samples_split = 2, num_features = None):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.num_features = num_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for i in range(self.num_trees):\n",
    "            tree = DecisionTreeRegressor(min_samples_split=self.min_samples_split, max_depth=self.max_depth)\n",
    "            X_sample, y_sample = bootstrap_sample(X,y)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        tree_preds = np.swapaxes(tree_preds, 0 ,1)\n",
    "        y_pred = [most_common_label(tree_pred) for tree_pred in tree_preds]\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "34dffd22-c417-4f0f-ad6e-ff4cf1c12c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[126.201 127.461 127.461 125.951]\n",
      "[126.201]\n",
      "[127.461 127.461 125.951]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[126.201 127.461 127.461 125.951]\n",
      "[126.201 125.951]\n",
      "[127.461 127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 125.951 127.461 127.591]\n",
      "[125.951 125.951]\n",
      "[127.461 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[125.951 125.951 127.461 127.591]\n",
      "[125.951 125.951 127.591]\n",
      "[127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[126.201 125.951 127.591 125.951]\n",
      "[126.201]\n",
      "[125.951 127.591 125.951]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[126.201 125.951 127.591 125.951]\n",
      "[126.201 125.951 125.951]\n",
      "[127.591]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[126.201 125.951 125.951]\n",
      "[126.201]\n",
      "[125.951 125.951]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D92980>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 127.591 126.201 127.591]\n",
      "[126.201]\n",
      "[125.951 127.591 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[125.951 127.591 126.201 127.591]\n",
      "[125.951 126.201]\n",
      "[127.591 127.591]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[127.591 127.461 126.201 127.591]\n",
      "[126.201]\n",
      "[127.591 127.461 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[127.591 127.461 126.201 127.591]\n",
      "[127.591 126.201 127.591]\n",
      "[127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[127.591 127.461 127.591]\n",
      "[127.591 127.591]\n",
      "[127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D92980>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 125.951 127.461 127.591]\n",
      "[125.951 125.951]\n",
      "[127.461 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[125.951 125.951 127.461 127.591]\n",
      "[125.951 125.951 127.591]\n",
      "[127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 127.591 126.201 126.201]\n",
      "[126.201 126.201]\n",
      "[125.951 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[125.951 127.591 126.201 126.201]\n",
      "[125.951 126.201 126.201]\n",
      "[127.591]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 126.201 126.201]\n",
      "[126.201 126.201]\n",
      "[125.951]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D92980>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 125.951 127.591 126.201]\n",
      "[126.201]\n",
      "[125.951 125.951 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[125.951 125.951 127.591 126.201]\n",
      "[125.951 125.951 126.201]\n",
      "[127.591]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 125.951 126.201]\n",
      "[126.201]\n",
      "[125.951 125.951]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D92980>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 126.201 125.951 127.461]\n",
      "[126.201]\n",
      "[125.951 125.951 127.461]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[125.951 126.201 125.951 127.461]\n",
      "[125.951 126.201 125.951]\n",
      "[127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[125.951 126.201 125.951]\n",
      "[126.201]\n",
      "[125.951 125.951]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D92980>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[126.201 126.201 125.951 125.951]\n",
      "[126.201 126.201]\n",
      "[125.951 125.951]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[127.461 127.591 126.201 125.951]\n",
      "[126.201]\n",
      "[127.461 127.591 125.951]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[127.461 127.591 126.201 125.951]\n",
      "[126.201 125.951]\n",
      "[127.461 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[127.461 127.591 126.201 125.951]\n",
      "[127.591 126.201 125.951]\n",
      "[127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[127.461 126.201 127.461 127.461]\n",
      "[126.201]\n",
      "[127.461 127.461 127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D92980>\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[127.461 127.461 126.201 126.201]\n",
      "[126.201 126.201]\n",
      "[127.461 127.461]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[127.591 127.591 126.201 126.201]\n",
      "[126.201 126.201]\n",
      "[127.591 127.591]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[126.201 125.951 127.591 126.201]\n",
      "[126.201 126.201]\n",
      "[125.951 127.591]\n",
      "dict_keys(['currFeatureIndex', 'threshold', 'variance_reduction', 'dataset_left', 'dataset_right'])\n",
      "[126.201 125.951 127.591 126.201]\n",
      "[126.201 125.951 126.201]\n",
      "[127.591]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D9D600>\n",
      "build_tree\n",
      "get best split\n",
      "num_features:5 currFeatureIndex:0\n",
      "dict_keys([])\n",
      "[126.201 125.951 126.201]\n",
      "[126.201 126.201]\n",
      "[125.951]\n",
      "num_features:5 currFeatureIndex:1\n",
      "num_features:5 currFeatureIndex:2\n",
      "num_features:5 currFeatureIndex:3\n",
      "num_features:5 currFeatureIndex:4\n",
      "<built-in method keys of dict object at 0x000001DC42D92980>\n",
      "build_tree\n",
      "build_tree\n",
      "build_tree\n",
      "Y_pred\n",
      "[126.481]\n"
     ]
    }
   ],
   "source": [
    "regressor = Random_Forest(min_samples_split=3, max_depth=3)\n",
    "regressor.fit(X_train,Y_train)\n",
    "Y_pred = regressor.predict(X_test)\n",
    "print('Y_pred')\n",
    "print(Y_pred)\n",
    "#print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec039f-96b0-40d9-98ef-ad564e9dd4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4cee7-30b1-4b47-afe6-3ef06291ed2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

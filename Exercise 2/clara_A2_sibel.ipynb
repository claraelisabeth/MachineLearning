{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression from Scratch\n",
    "\n",
    "Group 18 Members:\n",
    "\n",
    "- Clara Pichler, 11917694\n",
    "- Hannah Knapp, 11901857 \n",
    "- Sibel Toprakkiran, 09426341\n",
    "\n",
    "### Overview\n",
    "\n",
    "1. Bootstraping\n",
    "- `make_bootstraps(df, n_bootstraps=100)`\n",
    "\n",
    "2. Decision Tree Regression\n",
    "- `mse(y)`\n",
    "- `split_dataset(X, y, feature_idx, threshold)`\n",
    "- `find_best_split(X, y)`\n",
    "- `build_tree(X, y, max_depth, min_samples_split, depth=0)`\n",
    "- `predict_tree(tree, X)`\n",
    "\n",
    "3. Random Forest Regression\n",
    "\n",
    "4. Random Forest Regression - LLM\n",
    "- \n",
    "\n",
    "5. Evaluation\n",
    "- Ours\n",
    "- LLM\n",
    "- sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the data set `mountains_vs_beaches_preferences.csv` as a data frame for testing our functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52444 entries, 0 to 52443\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Age                           52444 non-null  int64  \n",
      " 1   Income                        52444 non-null  int64  \n",
      " 2   Travel_Frequency              52444 non-null  int64  \n",
      " 3   Vacation_Budget               52444 non-null  int64  \n",
      " 4   Proximity_to_Mountains        52444 non-null  int64  \n",
      " 5   Proximity_to_Beaches          52444 non-null  int64  \n",
      " 6   Pets                          52444 non-null  int64  \n",
      " 7   Environmental_Concerns        52444 non-null  int64  \n",
      " 8   Preference                    52444 non-null  int64  \n",
      " 9   Location_suburban             52444 non-null  bool   \n",
      " 10  Location_urban                52444 non-null  bool   \n",
      " 11  Favorite_Season_spring        52444 non-null  bool   \n",
      " 12  Favorite_Season_summer        52444 non-null  bool   \n",
      " 13  Favorite_Season_winter        52444 non-null  bool   \n",
      " 14  Gender_male                   52444 non-null  bool   \n",
      " 15  Gender_non-binary             52444 non-null  bool   \n",
      " 16  Preferred_Activities_Encoded  52444 non-null  float64\n",
      " 17  Education_Level_Encoded       52444 non-null  int64  \n",
      "dtypes: bool(7), float64(1), int64(10)\n",
      "memory usage: 4.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Age                             0\n",
       "Income                          0\n",
       "Travel_Frequency                0\n",
       "Vacation_Budget                 0\n",
       "Proximity_to_Mountains          0\n",
       "Proximity_to_Beaches            0\n",
       "Pets                            0\n",
       "Environmental_Concerns          0\n",
       "Preference                      0\n",
       "Location_suburban               0\n",
       "Location_urban                  0\n",
       "Favorite_Season_spring          0\n",
       "Favorite_Season_summer          0\n",
       "Favorite_Season_winter          0\n",
       "Gender_male                     0\n",
       "Gender_non-binary               0\n",
       "Preferred_Activities_Encoded    0\n",
       "Education_Level_Encoded         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Travel_Frequency</th>\n",
       "      <th>Vacation_Budget</th>\n",
       "      <th>Proximity_to_Mountains</th>\n",
       "      <th>Proximity_to_Beaches</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Environmental_Concerns</th>\n",
       "      <th>Preference</th>\n",
       "      <th>Location_suburban</th>\n",
       "      <th>Location_urban</th>\n",
       "      <th>Favorite_Season_spring</th>\n",
       "      <th>Favorite_Season_summer</th>\n",
       "      <th>Favorite_Season_winter</th>\n",
       "      <th>Gender_male</th>\n",
       "      <th>Gender_non-binary</th>\n",
       "      <th>Preferred_Activities_Encoded</th>\n",
       "      <th>Education_Level_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>71477</td>\n",
       "      <td>9</td>\n",
       "      <td>2477</td>\n",
       "      <td>175</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>88740</td>\n",
       "      <td>1</td>\n",
       "      <td>4777</td>\n",
       "      <td>228</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>46562</td>\n",
       "      <td>0</td>\n",
       "      <td>1469</td>\n",
       "      <td>71</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>99044</td>\n",
       "      <td>6</td>\n",
       "      <td>1482</td>\n",
       "      <td>31</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>106583</td>\n",
       "      <td>5</td>\n",
       "      <td>516</td>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Income  Travel_Frequency  Vacation_Budget  Proximity_to_Mountains  \\\n",
       "0   56   71477                 9             2477                     175   \n",
       "1   69   88740                 1             4777                     228   \n",
       "2   46   46562                 0             1469                      71   \n",
       "3   32   99044                 6             1482                      31   \n",
       "4   60  106583                 5              516                      23   \n",
       "\n",
       "   Proximity_to_Beaches  Pets  Environmental_Concerns  Preference  \\\n",
       "0                   267     0                       1           1   \n",
       "1                   190     0                       1           0   \n",
       "2                   280     0                       0           1   \n",
       "3                   255     1                       0           1   \n",
       "4                   151     1                       1           0   \n",
       "\n",
       "   Location_suburban  Location_urban  Favorite_Season_spring  \\\n",
       "0              False            True                   False   \n",
       "1               True           False                   False   \n",
       "2              False            True                   False   \n",
       "3              False           False                   False   \n",
       "4               True           False                   False   \n",
       "\n",
       "   Favorite_Season_summer  Favorite_Season_winter  Gender_male  \\\n",
       "0                    True                   False         True   \n",
       "1                   False                   False         True   \n",
       "2                   False                    True        False   \n",
       "3                    True                   False        False   \n",
       "4                   False                    True        False   \n",
       "\n",
       "   Gender_non-binary  Preferred_Activities_Encoded  Education_Level_Encoded  \n",
       "0              False                      0.500114                        1  \n",
       "1              False                      0.000000                        2  \n",
       "2              False                      0.500114                        2  \n",
       "3               True                      0.500916                        0  \n",
       "4              False                      0.000000                        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Preference\n",
       "0    39296\n",
       "1    13148\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pref = pd.read_csv('data/mountains_vs_beaches_preferences.csv')\n",
    "\n",
    "df_pref_one_hot = pd.get_dummies(df_pref, columns=['Location', 'Favorite_Season', 'Gender'], drop_first=True)\n",
    "\n",
    "target_mean = df_pref_one_hot.groupby('Preferred_Activities')['Preference'].mean()\n",
    "df_pref_one_hot['Preferred_Activities_Encoded'] = df_pref_one_hot['Preferred_Activities'].map(target_mean)\n",
    "\n",
    "education_mapping = {'high school': 0, 'bachelor': 1, 'master': 2, 'doctorate': 3}\n",
    "df_pref_one_hot['Education_Level_Encoded'] = df_pref_one_hot['Education_Level'].map(education_mapping)\n",
    "\n",
    "df_pref_one_hot = df_pref_one_hot.drop([\"Education_Level\", \"Preferred_Activities\"], axis=1)\n",
    "\n",
    "display(df_pref_one_hot.info())\n",
    "display(df_pref_one_hot.isnull().sum())\n",
    "display(df_pref_one_hot.head())\n",
    "\n",
    "display(df_pref_one_hot['Preference'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1503 entries, 0 to 1502\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x0      1503 non-null   int64  \n",
      " 1   x1      1503 non-null   float64\n",
      " 2   x2      1503 non-null   float64\n",
      " 3   x3      1503 non-null   float64\n",
      " 4   x4      1503 non-null   float64\n",
      " 5   y       1503 non-null   float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 70.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "x0    0\n",
       "x1    0\n",
       "x2    0\n",
       "x3    0\n",
       "x4    0\n",
       "y     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x0   x1      x2    x3        x4        y\n",
       "0   800  0.0  0.3048  71.3  0.002663  126.201\n",
       "1  1000  0.0  0.3048  71.3  0.002663  125.201\n",
       "2  1250  0.0  0.3048  71.3  0.002663  125.951\n",
       "3  1600  0.0  0.3048  71.3  0.002663  127.591\n",
       "4  2000  0.0  0.3048  71.3  0.002663  127.461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_airfol = pd.read_csv(\"./data/airfoil_noise_data.csv\")\n",
    "\n",
    "display(df_airfol.info())\n",
    "display(df_airfol.isnull().sum())\n",
    "display(df_airfol.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping is a method to create multiple subsets of the original data by sampling with replacement. Each subset is used to train one decision tree in the forest.\n",
    "\n",
    "- Introduces randomness, ensuring that trees see different views of the data.\n",
    "- Helps in reducing overfitting by decorrelating the trees.\n",
    "\n",
    "- __Sample Size__: The size of the bootstrap sample is the same as the original dataset.\n",
    "- __Replacement__: Sampling with replacement ensures diversity between bootstrapped samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bootstraps(df, n_bootstraps=100):\n",
    "    \n",
    "    dic_boot = {}\n",
    "    sample_size = df.shape[0]\n",
    "    idx = [i for i in range(sample_size)]\n",
    "\n",
    "    for b in range(n_bootstraps):\n",
    "        \n",
    "        sidx   = np.random.choice(idx,replace=True,size=sample_size)\n",
    "        b_samp = df.iloc[sidx,:]\n",
    "        \n",
    "        dic_boot['boot_'+str(b)] = {'boot':b_samp}\n",
    "    \n",
    "    return(dic_boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How our function `make_bootstraps` works:\n",
    "1. Each data point has equal probability of being selected \n",
    "2. Selecting data points from the original sample for the current bootstrap sample, with replacement! Until we reached the same size as the original data\n",
    "4. Repeating this process until we have `n_bootstraps` bootstrap samples which we save in a dictonary `dic_boot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_boot_pref = make_bootstraps(df_pref_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Travel_Frequency</th>\n",
       "      <th>Vacation_Budget</th>\n",
       "      <th>Proximity_to_Mountains</th>\n",
       "      <th>Proximity_to_Beaches</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Environmental_Concerns</th>\n",
       "      <th>Preference</th>\n",
       "      <th>Location_suburban</th>\n",
       "      <th>Location_urban</th>\n",
       "      <th>Favorite_Season_spring</th>\n",
       "      <th>Favorite_Season_summer</th>\n",
       "      <th>Favorite_Season_winter</th>\n",
       "      <th>Gender_male</th>\n",
       "      <th>Gender_non-binary</th>\n",
       "      <th>Preferred_Activities_Encoded</th>\n",
       "      <th>Education_Level_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19936</th>\n",
       "      <td>32</td>\n",
       "      <td>95402</td>\n",
       "      <td>4</td>\n",
       "      <td>3399</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10250</th>\n",
       "      <td>33</td>\n",
       "      <td>62734</td>\n",
       "      <td>5</td>\n",
       "      <td>4104</td>\n",
       "      <td>295</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35515</th>\n",
       "      <td>22</td>\n",
       "      <td>46106</td>\n",
       "      <td>8</td>\n",
       "      <td>4022</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.500916</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50737</th>\n",
       "      <td>38</td>\n",
       "      <td>110578</td>\n",
       "      <td>0</td>\n",
       "      <td>4791</td>\n",
       "      <td>299</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50138</th>\n",
       "      <td>68</td>\n",
       "      <td>64011</td>\n",
       "      <td>6</td>\n",
       "      <td>872</td>\n",
       "      <td>207</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500916</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Income  Travel_Frequency  Vacation_Budget  Proximity_to_Mountains  \\\n",
       "19936   32   95402                 4             3399                      18   \n",
       "10250   33   62734                 5             4104                     295   \n",
       "35515   22   46106                 8             4022                     255   \n",
       "50737   38  110578                 0             4791                     299   \n",
       "50138   68   64011                 6              872                     207   \n",
       "\n",
       "       Proximity_to_Beaches  Pets  Environmental_Concerns  Preference  \\\n",
       "19936                    64     1                       1           0   \n",
       "10250                    31     1                       0           0   \n",
       "35515                     0     1                       1           0   \n",
       "50737                   288     0                       0           0   \n",
       "50138                   263     1                       1           1   \n",
       "\n",
       "       Location_suburban  Location_urban  Favorite_Season_spring  \\\n",
       "19936              False           False                   False   \n",
       "10250              False            True                    True   \n",
       "35515               True           False                    True   \n",
       "50737               True           False                   False   \n",
       "50138              False            True                   False   \n",
       "\n",
       "       Favorite_Season_summer  Favorite_Season_winter  Gender_male  \\\n",
       "19936                    True                   False         True   \n",
       "10250                   False                   False        False   \n",
       "35515                   False                   False        False   \n",
       "50737                    True                   False         True   \n",
       "50138                   False                    True        False   \n",
       "\n",
       "       Gender_non-binary  Preferred_Activities_Encoded  \\\n",
       "19936              False                      0.000000   \n",
       "10250              False                      0.500916   \n",
       "35515              False                      0.500916   \n",
       "50737              False                      0.000000   \n",
       "50138               True                      0.500916   \n",
       "\n",
       "       Education_Level_Encoded  \n",
       "19936                        1  \n",
       "10250                        0  \n",
       "35515                        2  \n",
       "50737                        3  \n",
       "50138                        3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52444 entries, 19936 to 16920\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Age                           52444 non-null  int64  \n",
      " 1   Income                        52444 non-null  int64  \n",
      " 2   Travel_Frequency              52444 non-null  int64  \n",
      " 3   Vacation_Budget               52444 non-null  int64  \n",
      " 4   Proximity_to_Mountains        52444 non-null  int64  \n",
      " 5   Proximity_to_Beaches          52444 non-null  int64  \n",
      " 6   Pets                          52444 non-null  int64  \n",
      " 7   Environmental_Concerns        52444 non-null  int64  \n",
      " 8   Preference                    52444 non-null  int64  \n",
      " 9   Location_suburban             52444 non-null  bool   \n",
      " 10  Location_urban                52444 non-null  bool   \n",
      " 11  Favorite_Season_spring        52444 non-null  bool   \n",
      " 12  Favorite_Season_summer        52444 non-null  bool   \n",
      " 13  Favorite_Season_winter        52444 non-null  bool   \n",
      " 14  Gender_male                   52444 non-null  bool   \n",
      " 15  Gender_non-binary             52444 non-null  bool   \n",
      " 16  Preferred_Activities_Encoded  52444 non-null  float64\n",
      " 17  Education_Level_Encoded       52444 non-null  int64  \n",
      "dtypes: bool(7), float64(1), int64(10)\n",
      "memory usage: 5.2 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dic_boot_pref['boot_0']['boot'].head(5))\n",
    "display(dic_boot_pref['boot_0']['boot'].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "19386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "19334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "duplicates_boot_0 = dic_boot_pref['boot_0']['boot'].duplicated()\n",
    "display(duplicates_boot_0.sum())\n",
    "display(dic_boot_pref['boot_1']['boot'].duplicated().sum())\n",
    "display(dic_boot_pref['boot_2']['boot'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the functions to split the data and calculate metrics like the mean squared error (MSE).\n",
    "And for the actual building of the trees we recursively split the data into smaller groups, based on feature thresholds, until a stopping condition is met (e.g., max depth or minimum samples per leaf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y):\n",
    "    return np.mean((y - np.mean(y))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_split(y_left, y_right):\n",
    "\n",
    "    total = len(y_left) + len(y_right)\n",
    "    weighted_mse = (len(y_left) * mse(y_left) + len(y_right) * mse(y_right)) / total\n",
    "\n",
    "    return weighted_mse\n",
    "\n",
    "\n",
    "def variance_reduction_split(y_left, y_right):\n",
    "\n",
    "    total = len(y_left) + len(y_right)\n",
    "    parent_variance = np.var(np.concatenate([y_left, y_right]))\n",
    "    weighted_variance = (len(y_left) * np.var(y_left) + len(y_right) * np.var(y_right)) / total\n",
    "\n",
    "    return parent_variance - weighted_variance\n",
    "\n",
    "\n",
    "def mae_split(y_left, y_right):\n",
    "\n",
    "    total = len(y_left) + len(y_right)\n",
    "    weighted_mae = (len(y_left) * np.mean(np.abs(y_left - np.mean(y_left))) +\n",
    "                    len(y_right) * np.mean(np.abs(y_right - np.mean(y_right)))) / total\n",
    "    \n",
    "    return weighted_mae\n",
    "\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    \n",
    "    value_counts = np.unique(y, return_counts=True)[1]\n",
    "    probabilities = value_counts / len(y)\n",
    "    \n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "\n",
    "def information_gain(y_parent, y_left, y_right):\n",
    "\n",
    "    n_total = len(y_parent)\n",
    "    n_left = len(y_left)\n",
    "    n_right = len(y_right)\n",
    "    \n",
    "    if n_left == 0 or n_right == 0:\n",
    "        return 0  # No information gain if one side is empty\n",
    "    \n",
    "    parent_entropy = entropy(y_parent)\n",
    "    weighted_child_entropy = (n_left / n_total) * entropy(y_left) + (n_right / n_total) * entropy(y_right)\n",
    "    \n",
    "    return parent_entropy - weighted_child_entropy\n",
    "\n",
    "\n",
    "def information_gain_split(y_left, y_right):\n",
    "    \n",
    "    return -information_gain(np.concatenate([y_left, y_right]), y_left, y_right)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mse(y)` calculates how spread out the data points are from their mean. A lower MSE indicates that the values in `y` are closer to the mean, which means the split effectively reduces variability. \n",
    "\n",
    "**Mean Squared Error (MSE)**\n",
    "\n",
    "- **Definition**: Measures the average squared difference between the predicted and actual values.\n",
    "- **Usage**: Best suited for regression problems where the target is continuous.\n",
    "- **Pros**: Penalizes larger errors more than smaller ones, making it sensitive to outliers.\n",
    "- **Cons**: Overly sensitive to outliers.\n",
    "\n",
    "\n",
    "\n",
    "**Variance Reduction**\n",
    "\n",
    "- **Definition**: Measures how much the variance of the target variable decreases when the data is split.\n",
    "- **Formula**:\n",
    "  \\[\n",
    "  \\text{Variance Reduction} = \\text{Variance (parent)} - \\text{Weighted Variance (left and right children)}\n",
    "  \\]\n",
    "  Variance is calculated as:\n",
    "  \\[\n",
    "  \\text{Variance} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\bar{y})^2\n",
    "  \\]\n",
    "- **Usage**: Another metric for regression, similar to MSE but focuses on reducing variance.\n",
    "- **Pros**: Intuitive and directly measures how well a split homogenizes the data.\n",
    "- **Cons**: Can be slower to compute compared to simpler metrics.\n",
    "\n",
    "\n",
    "\n",
    "**Reduction in Standard Deviation (SD Reduction)**\n",
    "- **Definition**: Measures the reduction in standard deviation after the split.\n",
    "- **Formula**:\n",
    "  \\[\n",
    "  \\text{SD Reduction} = \\text{Standard Deviation (parent)} - \\text{Weighted SD (left and right children)}\n",
    "  \\]\n",
    "- **Usage**: Also for regression; directly interprets spread in the target.\n",
    "- **Pros**: Similar to variance reduction but easier to interpret since it's in the same units as the target.\n",
    "- **Cons**: Like variance reduction, it may still suffer if the data has extreme outliers.\n",
    "\n",
    "\n",
    "\n",
    "**Information Gain**\n",
    "\n",
    "- **Definition**: Measures the reduction in entropy (uncertainty) of the target after a split.\n",
    "- **Formula**:\n",
    "  \\[\n",
    "  \\text{Information Gain} = \\text{Entropy (parent)} - \\text{Weighted Entropy (left and right children)}\n",
    "  \\]\n",
    "  Where entropy is:\n",
    "  \\[\n",
    "  \\text{Entropy} = - \\sum_{i} p_i \\log_2(p_i)\n",
    "  \\]\n",
    "  Here, \\( p_i \\) is the proportion of each class.\n",
    "- **Usage**: Often used for classification, but can be adapted for regression using a continuous version of entropy.\n",
    "- **Pros**: Captures the \"uncertainty reduction\" of a split.\n",
    "- **Cons**: Computationally intensive for large datasets or many splits.\n",
    "\n",
    "\n",
    "\n",
    "**Which Metric Should You Use?**\n",
    "\n",
    "   - **MSE** or **Variance Reduction**: Best for datasets without significant outliers.\n",
    "   - **MAE**: Better for datasets with outliers or non-symmetric error distributions.\n",
    "   - **SD Reduction**: Useful if you want an intuitive measure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y, feature_idx, threshold):\n",
    "    \n",
    "    left_mask = X[:, feature_idx] <= threshold\n",
    "    right_mask = ~left_mask\n",
    "\n",
    "    return X[left_mask], X[right_mask], y[left_mask], y[right_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split_dataset` divides X (features) and y (target) into two groups based on whether the value of a feature is less than or equal to a given threshold. This is used to evaluate potential splits during training. For example split on feature `Unemployment` at value 6 creates two groups: rows where `Unemployment <= 6` and rows where `Unemployment > 6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(X, y, feature_subset=None, metric=\"mse\"):\n",
    "    print('find best split')\n",
    "    best_feature, best_threshold = None, None\n",
    "    best_metric_value = -float(\"inf\")\n",
    "    features = feature_subset if feature_subset is not None else range(X.shape[1])\n",
    "\n",
    "    metric_functions = {\n",
    "        \"mse\": mse_split,\n",
    "        \"variance_reduction\": variance_reduction_split,\n",
    "        \"mae\": mae_split,\n",
    "        \"information_gain\": information_gain_split,\n",
    "    }\n",
    "    \n",
    "    metric_function = metric_functions[metric]\n",
    "    \n",
    "    for feature_idx in features:\n",
    "        thresholds = np.unique(X[:, feature_idx])\n",
    "        print('thresholds')\n",
    "        print(thresholds)\n",
    "        for threshold in thresholds:\n",
    "            _, _, y_left, y_right = split_dataset(X, y, feature_idx, threshold)\n",
    "            \n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "            \n",
    "            metric_value = metric_function(y_left, y_right)\n",
    "            print('metric_value =' + str(metric_value))\n",
    "            print('best_metric_value =' + str(best_metric_value))\n",
    "            if metric_value > best_metric_value:\n",
    "                best_metric_value = metric_value\n",
    "                best_feature = feature_idx\n",
    "                best_threshold = threshold\n",
    "    \n",
    "    return best_feature, best_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_best_split` evaluates all possible splits for every feature and every threshold. It selects the split according to the metric that was given to it.\n",
    "\n",
    "The output is the `best_feature` (column index of the splitting feature) and the `best_threshold` (value of the feature where the split happens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X, y, max_depth, min_samples_split, depth=0, metric=\"mse\"):\n",
    "    print('max_depth ' + str(max_depth))\n",
    "    print('min_samples_split ' + str(min_samples_split))\n",
    "    if depth >= max_depth or len(y) < min_samples_split: # or mse(y) == 0:\n",
    "        print('thats a node')\n",
    "        return np.mean(y)  \n",
    "\n",
    "    n_features = X.shape[1]\n",
    "    #feature_subset = np.random.choice(n_features, size=int(np.sqrt(n_features)), replace=False)\n",
    "    feature_subset = np.random.choice(n_features, size=int(n_features), replace=False)\n",
    "    print(feature_subset)\n",
    "    feature_idx, threshold = find_best_split(X, y, feature_subset, metric=metric)\n",
    "    \n",
    "    if feature_idx is None:\n",
    "        return np.mean(y)  \n",
    "    \n",
    "    X_left, X_right, y_left, y_right = split_dataset(X, y, feature_idx, threshold)\n",
    "    print('X-left')\n",
    "    print(X_left)\n",
    "    print('Y-left')\n",
    "    print(X_right)\n",
    "    left_subtree = build_tree(X_left, y_left, max_depth, min_samples_split, depth + 1, metric)\n",
    "    right_subtree = build_tree(X_right, y_right, max_depth, min_samples_split, depth + 1, metric)\n",
    "    \n",
    "    return {\n",
    "        \"feature_idx\": feature_idx,\n",
    "        \"threshold\": threshold,\n",
    "        \"left\": left_subtree,\n",
    "        \"right\": right_subtree,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Stopping Conditions__: Stops if the max depth is reached, if there are fewer samples than min_samples_split, or if the MSE is 0 (all values are the same).\n",
    "- __Recursive Splitting__: For each split, the function creates a left and right subtree until the stopping conditions are met.\n",
    "- __Leaf Node__: If the recursion stops, the tree stores the mean value of y for prediction.\n",
    "- __Feature Selection__: Chooses $\\sqrt{n}$ features randomly for each tree, where $n$ is the number of original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(tree, X):\n",
    "\n",
    "    if isinstance(tree, dict):\n",
    "\n",
    "        feature_idx = tree[\"feature_idx\"]\n",
    "        threshold = tree[\"threshold\"]\n",
    "\n",
    "        if X[feature_idx] <= threshold:\n",
    "            return predict_tree(tree[\"left\"], X)\n",
    "        \n",
    "        else:\n",
    "            return predict_tree(tree[\"right\"], X)\n",
    "        \n",
    "    else:\n",
    "        return tree  # Leaf node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traverses the tree based on the input features until you reach a leaf node.\n",
    "Returns the mean value of the target variable y at the leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegressor_18:\n",
    "    \n",
    "    def __init__(self, n_trees=10, max_depth=5, min_samples_split=10, metric=\"mse\"):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "        self.metric = metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        bootstraps = make_bootstraps(pd.DataFrame(np.hstack((X, y[:, None]))), n_bootstraps=self.n_trees)\n",
    "\n",
    "        for b in range(self.n_trees):\n",
    "            print('tree ' + str(b))\n",
    "            print('----------------')\n",
    "            bootstrap = bootstraps[f'boot_{b}']['boot']\n",
    "            X_boot = bootstrap.iloc[:, :-1].values\n",
    "            y_boot = bootstrap.iloc[:, -1].values\n",
    "            print(X_boot)\n",
    "            print(y_boot)\n",
    "            tree = build_tree(X_boot, y_boot, self.max_depth, self.min_samples_split, metric=self.metric)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.array([predict_tree(tree, x) for x in X for tree in self.trees])\n",
    "        predictions = predictions.reshape(self.n_trees, len(X))\n",
    "\n",
    "        return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use for the comparison of the methods the same holdout split with the training set containg 75% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_pref_one_hot.drop(\"Preference\", axis=1).values\n",
    "# y = df_pref_one_hot[\"Preference\"].values\n",
    "df_airfol = df_airfol.head(5)\n",
    "X = df_airfol.drop(\"y\", axis=1).values\n",
    "y = df_airfol[\"y\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation we use the following three methods:\n",
    "\n",
    "__Mean Squared Error (MSE)__\n",
    "\n",
    "The average of the squared differences between the predicted values and the actual values. It gives more weight to larger errors.\n",
    "\n",
    "- A smaller MSE value indicates that the modelâ€™s predictions are close to the actual values.\n",
    "- Since it's based on squared differences, large prediction errors (outliers) have a greater impact.\n",
    "- MSE is in the square of the unit of your target variable\n",
    "- Useful when large errors are particularly undesirable and need to be penalized more heavily.\n",
    "\n",
    "\n",
    "\n",
    "__Mean Absolute Error (MAE)__\n",
    "\n",
    "The average of the absolute differences between predicted values and actual values. Unlike MSE, it treats all errors equally, regardless of size.\n",
    "\n",
    "- A smaller MAE value indicates better model performance.\n",
    "- MAE is in the same unit as the target variable, making it more interpretable compared to MSE.\n",
    "- Good for understanding the typical size of prediction errors.\n",
    "- Less sensitive to outliers compared to MSE.\n",
    "\n",
    "__R-squared__\n",
    "\n",
    "The proportion of variance in the target variable that the model explains. It ranges from:\n",
    "- __1__: Perfect fit (model explains all variance in the data).\n",
    "- __0__: Model does no better than predicting the mean of the target.\n",
    "- __Negative__: Model performs worse than simply predicting the mean.\n",
    "\n",
    "\n",
    "- A higher R-squared (close to 1) indicates a good fit.\n",
    "- A low or negative R-squared suggests that your model is not capturing the relationship between the features and target effectively.\n",
    "- Helps understand how well the model explains the variability in the target variable.\n",
    "- Not ideal for measuring absolute error but useful for comparing models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree 0\n",
      "----------------\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[127.591 126.201 125.951]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[0 1 3 4 2]\n",
      "find best split\n",
      "thresholds\n",
      "[ 800. 1250. 1600.]\n",
      "metric_value =0.0722000000000001\n",
      "best_metric_value =-inf\n",
      "metric_value =0.5100500000000004\n",
      "best_metric_value =0.0722000000000001\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[1 0 2 3 4]\n",
      "find best split\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[ 800. 1250.]\n",
      "metric_value =0.015625\n",
      "best_metric_value =-inf\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[3 0 2 1 4]\n",
      "find best split\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[800.]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[3 0 1 4 2]\n",
      "find best split\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[1250.]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[0 2 4 1 3]\n",
      "find best split\n",
      "thresholds\n",
      "[1600.]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[71.3]\n",
      "tree 1\n",
      "----------------\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[127.591 127.591 127.591]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[0 1 4 2 3]\n",
      "find best split\n",
      "thresholds\n",
      "[1600.]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[71.3]\n",
      "tree 2\n",
      "----------------\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[126.201 125.951 125.951]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[0 3 2 1 4]\n",
      "find best split\n",
      "thresholds\n",
      "[ 800. 1250.]\n",
      "metric_value =0.01388888888888889\n",
      "best_metric_value =-inf\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[3 4 1 2 0]\n",
      "find best split\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[800.]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[1 0 3 4 2]\n",
      "find best split\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[1250.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "tree 3\n",
      "----------------\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[126.201 127.591 125.951]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[4 3 1 0 2]\n",
      "find best split\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[ 800. 1250. 1600.]\n",
      "metric_value =0.0722000000000001\n",
      "best_metric_value =-inf\n",
      "metric_value =0.5100500000000004\n",
      "best_metric_value =0.0722000000000001\n",
      "thresholds\n",
      "[0.3048]\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[3 0 2 1 4]\n",
      "find best split\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[ 800. 1250.]\n",
      "metric_value =0.015625\n",
      "best_metric_value =-inf\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[1 4 0 3 2]\n",
      "find best split\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[800.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.3048]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[3 2 1 0 4]\n",
      "find best split\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[1250.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[2 4 1 0 3]\n",
      "find best split\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[1600.]\n",
      "thresholds\n",
      "[71.3]\n",
      "tree 4\n",
      "----------------\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[125.951 126.201 126.201]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[1 4 0 2 3]\n",
      "find best split\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[ 800. 1250.]\n",
      "metric_value =0.013888888888888888\n",
      "best_metric_value =-inf\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[71.3]\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[2 3 4 0 1]\n",
      "find best split\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[800.]\n",
      "thresholds\n",
      "[0.]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[3 0 1 4 2]\n",
      "find best split\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[1250.]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "tree 5\n",
      "----------------\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[127.591 127.591 126.201]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[2 0 1 4 3]\n",
      "find best split\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[ 800. 1600.]\n",
      "metric_value =0.42935555555555593\n",
      "best_metric_value =-inf\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[71.3]\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[3 0 4 1 2]\n",
      "find best split\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[800.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.3048]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[0 3 1 4 2]\n",
      "find best split\n",
      "thresholds\n",
      "[1600.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "tree 6\n",
      "----------------\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[127.591 126.201 127.591]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[4 2 0 3 1]\n",
      "find best split\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[ 800. 1600.]\n",
      "metric_value =0.42935555555555593\n",
      "best_metric_value =-inf\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.]\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[0 1 3 4 2]\n",
      "find best split\n",
      "thresholds\n",
      "[800.]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[4 1 0 3 2]\n",
      "find best split\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[1600.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.3048]\n",
      "tree 7\n",
      "----------------\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[125.951 127.591 126.201]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[0 1 2 4 3]\n",
      "find best split\n",
      "thresholds\n",
      "[ 800. 1250. 1600.]\n",
      "metric_value =0.0722000000000001\n",
      "best_metric_value =-inf\n",
      "metric_value =0.5100500000000004\n",
      "best_metric_value =0.0722000000000001\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[71.3]\n",
      "X-left\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[2 1 3 4 0]\n",
      "find best split\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[ 800. 1250.]\n",
      "metric_value =0.015625\n",
      "best_metric_value =-inf\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[1 3 2 4 0]\n",
      "find best split\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[800.]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[2 1 0 3 4]\n",
      "find best split\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[1250.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[3 0 1 4 2]\n",
      "find best split\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[1600.]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "tree 8\n",
      "----------------\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[125.951 127.591 125.951]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[0 3 1 2 4]\n",
      "find best split\n",
      "thresholds\n",
      "[1250. 1600.]\n",
      "metric_value =0.5976888888888893\n",
      "best_metric_value =-inf\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "X-left\n",
      "[[1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.25000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[2 1 4 0 3]\n",
      "find best split\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[1250.]\n",
      "thresholds\n",
      "[71.3]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[4 0 2 3 1]\n",
      "find best split\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[1600.]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.]\n",
      "tree 9\n",
      "----------------\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "[126.201 127.591 126.201]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[4 2 1 3 0]\n",
      "find best split\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[ 800. 1600.]\n",
      "metric_value =0.42935555555555593\n",
      "best_metric_value =-inf\n",
      "X-left\n",
      "[[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
      " [8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "Y-left\n",
      "[[1.60000e+03 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[0 1 4 3 2]\n",
      "find best split\n",
      "thresholds\n",
      "[800.]\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[71.3]\n",
      "thresholds\n",
      "[0.3048]\n",
      "max_depth 5\n",
      "min_samples_split 1\n",
      "[1 2 0 4 3]\n",
      "find best split\n",
      "thresholds\n",
      "[0.]\n",
      "thresholds\n",
      "[0.3048]\n",
      "thresholds\n",
      "[1600.]\n",
      "thresholds\n",
      "[0.00266337]\n",
      "thresholds\n",
      "[71.3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([126.607, 127.263])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_18 = RandomForestRegressor_18(n_trees=10, max_depth=5, min_samples_split=1, metric=\"variance_reduction\")\n",
    "rf_18.fit(X_train, y_train)\n",
    "\n",
    "predictions_18 = rf_18.predict(X_test)\n",
    "predictions_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Mean Squared Error: 1.01\n",
      "Mean Absolute Error: 0.80\n",
      "R-squared: 0.21\n"
     ]
    }
   ],
   "source": [
    "mse_18 = mean_squared_error(y_test, predictions_18)\n",
    "mae_18 = mean_absolute_error(y_test, predictions_18)\n",
    "r2_18 = r2_score(y_test, predictions_18)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"Mean Squared Error: {mse_18:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_18:.2f}\")\n",
    "print(f\"R-squared: {r2_18:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SkLearn Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_sklearn = RandomForestRegressor(n_estimators=10, max_depth = 5, min_samples_split = 2)\n",
    "rf_sklearn.fit(X_train, y_train)\n",
    "\n",
    "predictions_sklearn = rf_sklearn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Mean Squared Error: 0.45\n",
      "Mean Absolute Error: 0.49\n",
      "R-squared: 0.65\n"
     ]
    }
   ],
   "source": [
    "mse_sklearn = mean_squared_error(y_test, predictions_sklearn)\n",
    "mae_sklearn = mean_absolute_error(y_test, predictions_sklearn)\n",
    "r2_sklearn = r2_score(y_test, predictions_sklearn)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"Mean Squared Error: {mse_sklearn:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_sklearn:.2f}\")\n",
    "print(f\"R-squared: {r2_sklearn:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Depth: Prevents trees from growing too deep, which could lead to overfitting.\n",
    "\n",
    "Min Samples Split: Controls the smallest group size allowed for further splitting, preventing unnecessary splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Key Insights from These Metrics**\n",
    "1. **MSE**:\n",
    "   - If it's high, your model is making some large errors that need to be addressed.\n",
    "   - If it's low, your model is capturing most of the relationship.\n",
    "\n",
    "2. **MAE**:\n",
    "   - Directly tells you the average prediction error. \n",
    "   - Compare it to the scale of your target variable; if MAE is relatively low, the model is performing well.\n",
    "\n",
    "3. **RÂ²**:\n",
    "   - A high RÂ² suggests the model explains a significant portion of the target variable's variance.\n",
    "   - If RÂ² is low (or negative), consider if the features are truly predictive of the target or if the model is too simple/complex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next Steps Based on Metrics**\n",
    "\n",
    "- **High MSE or MAE**:\n",
    "  - Investigate outliers, or whether the model needs better hyperparameter tuning.\n",
    "  - Consider adding more predictive features or improving feature engineering.\n",
    "\n",
    "- **Low RÂ²**:\n",
    "  - Evaluate if features are relevant or add more features to capture the variance.\n",
    "  - Consider if the model is underfitting or overfitting:\n",
    "    - Underfitting: Increase `max_depth`, add more `n_trees`.\n",
    "    - Overfitting: Decrease `max_depth` or regularize.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
